{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FakeNews Detection with just News Features BERT.ipynb","provenance":[{"file_id":"https://github.com/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb","timestamp":1571609284061}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"dCpvgG0vwXAZ","colab_type":"text"},"source":["#Fake News Detection with BERT on TF Hub"]},{"cell_type":"markdown","metadata":{"id":"xiYrZKaHwV81","colab_type":"text"},"source":["Now that BERT's been added to [TF Hub](https://www.tensorflow.org/hub) as a loadable module, it's easy(ish) to add into existing Tensorflow text pipelines. In an existing pipeline, BERT can replace text embedding layers like ELMO and GloVE. Alternatively, [finetuning](http://wiki.fast.ai/index.php/Fine_tuning) BERT can provide both an accuracy boost and faster training time in many cases.\n","\n","Here, we'll train a model to predict whether a news article is fake or not. Code was adapted from [this colab notebook](https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb)."]},{"cell_type":"code","metadata":{"id":"hsZvic2YxnTz","colab_type":"code","outputId":"9aee3ec2-19be-431a-fed0-49463709cb12","executionInfo":{"status":"ok","timestamp":1575561609845,"user_tz":480,"elapsed":3076,"user":{"displayName":"Divya Sudhakar","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBAEe8lSbL-gO8W2QGjfXvHbFVw-wl2B28bQD3_6_A=s64","userId":"13661723492181317645"}},"colab":{"base_uri":"https://localhost:8080/","height":63}},"source":["from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from datetime import datetime"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"cp5wfXDx5SPH","colab_type":"text"},"source":["In addition to the standard libraries we imported above, we'll need to install BERT's python package."]},{"cell_type":"code","metadata":{"id":"jviywGyWyKsA","colab_type":"code","outputId":"412e0615-f994-4b44-a20d-e47269ae5554","executionInfo":{"status":"ok","timestamp":1575561616907,"user_tz":480,"elapsed":6186,"user":{"displayName":"Divya Sudhakar","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBAEe8lSbL-gO8W2QGjfXvHbFVw-wl2B28bQD3_6_A=s64","userId":"13661723492181317645"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["!pip install bert-tensorflow"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting bert-tensorflow\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n","\r\u001b[K     |████▉                           | 10kB 22.1MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 61kB 6.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.2MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n","Installing collected packages: bert-tensorflow\n","Successfully installed bert-tensorflow-1.0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hhbGEfwgdEtw","colab_type":"code","outputId":"258d42ef-08b4-44cb-afd6-40244ed7d261","executionInfo":{"status":"ok","timestamp":1575561616910,"user_tz":480,"elapsed":4561,"user":{"displayName":"Divya Sudhakar","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBAEe8lSbL-gO8W2QGjfXvHbFVw-wl2B28bQD3_6_A=s64","userId":"13661723492181317645"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["import bert\n","from bert import run_classifier\n","from bert import optimization\n","from bert import tokenization"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KVB3eOcjxxm1","colab_type":"text"},"source":["Below, we'll set an output directory location to store our model output and checkpoints. This can be a local directory, in which case you'd set OUTPUT_DIR to the name of the directory you'd like to create. If you're running this code in Google's hosted Colab, the directory won't persist after the Colab session ends.\n","\n","Alternatively, if you're a GCP user, you can store output in a GCP bucket. To do that, set a directory name in OUTPUT_DIR and the name of the GCP bucket in the BUCKET field.\n","\n","Set DO_DELETE to rewrite the OUTPUT_DIR if it exists. Otherwise, Tensorflow will load existing model checkpoints from that directory (if they exist)."]},{"cell_type":"code","metadata":{"id":"US_EAnICvP7f","colab_type":"code","outputId":"300f151f-8f9f-4c31-ed60-e069b6fc2dc5","cellView":"form","executionInfo":{"status":"ok","timestamp":1575561621634,"user_tz":480,"elapsed":908,"user":{"displayName":"Divya Sudhakar","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBAEe8lSbL-gO8W2QGjfXvHbFVw-wl2B28bQD3_6_A=s64","userId":"13661723492181317645"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Set the output directory for saving model file\n","# Optionally, set a GCP bucket location\n","\n","OUTPUT_DIR = 'model_out'#@param {type:\"string\"}\n","#@markdown Whether or not to clear/delete the directory and create a new one\n","DO_DELETE = False #@param {type:\"boolean\"}\n","#@markdown Set USE_BUCKET and BUCKET if you want to (optionally) store model output on GCP bucket.\n","USE_BUCKET = False #@param {type:\"boolean\"}\n","BUCKET = 'BUCKET_NAME' #@param {type:\"string\"}\n","\n","if USE_BUCKET:\n","  OUTPUT_DIR = 'gs://{}/{}'.format(BUCKET, OUTPUT_DIR)\n","  from google.colab import auth\n","  auth.authenticate_user()\n","\n","if DO_DELETE:\n","  try:\n","    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n","  except:\n","    # Doesn't matter if the directory didn't exist\n","    pass\n","tf.gfile.MakeDirs(OUTPUT_DIR)\n","print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["***** Model output directory: model_out *****\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pmFYvkylMwXn","colab_type":"text"},"source":["#Data"]},{"cell_type":"code","metadata":{"id":"fom_ff20gyy6","colab_type":"code","colab":{}},"source":["from tensorflow import keras\n","import os\n","import re\n","from google.colab import drive\n","\n","\n","# Download and process the dataset files.\n","def download_and_load_datasets(force_download=False):\n","  drive.mount('/content/drive')\n","  unpickled_df = pd.read_pickle('/content/drive/My Drive/FakeNewsNet-master/Downloaded Datasets/fakenewsnet_dataset_content.pkl')\n","  unpickled_df = unpickled_df.drop_duplicates('id')\n","  unpickled_df = unpickled_df.sample(frac=1).reset_index(drop=True)\n","  unpickled_df.drop(['id'], axis=1, inplace=True)\n","  train_df = unpickled_df[0:20000]\n","  dev_df = unpickled_df[20000:21000]\n","  test_df = unpickled_df[21000:]\n"," \n","  return train_df, dev_df, test_df\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2abfwdn-g135","colab_type":"code","outputId":"d70ba44f-fb86-4741-ba97-d8ec7eee02d3","executionInfo":{"status":"ok","timestamp":1572927106311,"user_tz":480,"elapsed":37962,"user":{"displayName":"Divya Sudhakar","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBAEe8lSbL-gO8W2QGjfXvHbFVw-wl2B28bQD3_6_A=s64","userId":"13661723492181317645"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["train, dev, test = download_and_load_datasets()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"prRQM8pDi8xI","colab_type":"code","outputId":"e863ae94-2271-4db9-818a-e8f0f914b63b","executionInfo":{"status":"ok","timestamp":1572927113676,"user_tz":480,"elapsed":668,"user":{"displayName":"Divya Sudhakar","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBAEe8lSbL-gO8W2QGjfXvHbFVw-wl2B28bQD3_6_A=s64","userId":"13661723492181317645"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train.columns"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['label', 'title', 'source', 'text'], dtype='object')"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"sfRnHSz3iSXz","colab_type":"text"},"source":["For us, our input data is the 'text' and 'titile' columns and our label is the 'label' column."]},{"cell_type":"code","metadata":{"id":"IuMOGwFui4it","colab_type":"code","colab":{}},"source":["# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n","label_list = [True, False]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V399W0rqNJ-Z","colab_type":"text"},"source":["#Data Preprocessing\n","We'll need to transform our data into a format BERT understands. This involves two steps. First, we create  `InputExample`'s using the constructor provided in the BERT library.\n","\n","- `text_a` is the text we want to classify, which in this case, is the `Request` field in our Dataframe. \n","- `text_b` is used if we're training a model to understand the relationship between sentences (i.e. is `text_b` a translation of `text_a`? Is `text_b` an answer to the question asked by `text_a`?). This doesn't apply to our task, so we can leave `text_b` blank.\n","- `label` is the label for our example, i.e. True, False"]},{"cell_type":"code","metadata":{"id":"p9gEt5SmM6i6","colab_type":"code","colab":{}},"source":["# Use the InputExample class from BERT's run_classifier code to create examples from the data\n","train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n","                                                                   text_a = x['title'] + x['text'], \n","                                                                   text_b = None, \n","                                                                   label = x['label']), axis = 1)\n","\n","dev_InputExamples = dev.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n","                                                                   text_a = x['title'] + x['text'], \n","                                                                   text_b = None, \n","                                                                   label = x['label']), axis = 1)\n","\n","test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n","                                                                   text_a = x['title'] + x['text'], \n","                                                                   text_b = None, \n","                                                                   label = x['label']), axis = 1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SCZWZtKxObjh","colab_type":"text"},"source":["Next, we need to preprocess our data so that it matches the data BERT was trained on. For this, we'll need to do a couple of things (but don't worry--this is also included in the Python library):\n","\n","\n","1. Lowercase our text (if we're using a BERT lowercase model)\n","2. Tokenize it (i.e. \"sally says hi\" -> [\"sally\", \"says\", \"hi\"])\n","3. Break words into WordPieces (i.e. \"calling\" -> [\"call\", \"##ing\"])\n","4. Map our words to indexes using a vocab file that BERT provides\n","5. Add special \"CLS\" and \"SEP\" tokens (see the [readme](https://github.com/google-research/bert))\n","6. Append \"index\" and \"segment\" tokens to each input (see the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf))\n","\n","Happily, we don't have to worry about most of these details.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qMWiDtpyQSoU","colab_type":"text"},"source":["To start, we'll need to load a vocabulary file and lowercasing information directly from the BERT tf hub module:"]},{"cell_type":"code","metadata":{"id":"IhJSe0QHNG7U","colab_type":"code","outputId":"b80a5d14-21f0-4d58-e345-bee4f2187542","executionInfo":{"status":"ok","timestamp":1572927138641,"user_tz":480,"elapsed":14361,"user":{"displayName":"Divya Sudhakar","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBAEe8lSbL-gO8W2QGjfXvHbFVw-wl2B28bQD3_6_A=s64","userId":"13661723492181317645"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["# This is a path to an uncased (all lowercase) version of BERT\n","BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n","\n","def create_tokenizer_from_hub_module():\n","  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n","  with tf.Graph().as_default():\n","    bert_module = hub.Module(BERT_MODEL_HUB)\n","    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n","    with tf.Session() as sess:\n","      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n","                                            tokenization_info[\"do_lower_case\"]])\n","      \n","  return bert.tokenization.FullTokenizer(\n","      vocab_file=vocab_file, do_lower_case=do_lower_case)\n","\n","tokenizer = create_tokenizer_from_hub_module()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"z4oFkhpZBDKm","colab_type":"text"},"source":["Great--we just learned that the BERT model we're using expects lowercase data (that's what stored in tokenization_info[\"do_lower_case\"]) and we also loaded BERT's vocab file. We also created a tokenizer, which breaks words into word pieces:"]},{"cell_type":"code","metadata":{"id":"dsBo6RCtQmwx","colab_type":"code","outputId":"bec6a463-1e1c-4d4b-aa2d-94d4aa3e580c","executionInfo":{"status":"ok","timestamp":1572884748113,"user_tz":480,"elapsed":1122,"user":{"displayName":"Divya Sudhakar","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBAEe8lSbL-gO8W2QGjfXvHbFVw-wl2B28bQD3_6_A=s64","userId":"13661723492181317645"}},"colab":{"base_uri":"https://localhost:8080/","height":340}},"source":["tokenizer.tokenize(\"This here's an example of using the BERT tokenizer!! Here is the text.\")"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['this',\n"," 'here',\n"," \"'\",\n"," 's',\n"," 'an',\n"," 'example',\n"," 'of',\n"," 'using',\n"," 'the',\n"," 'bert',\n"," 'token',\n"," '##izer',\n"," '!',\n"," '!',\n"," 'here',\n"," 'is',\n"," 'the',\n"," 'text',\n"," '.']"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"0OEzfFIt6GIc","colab_type":"text"},"source":["Using our tokenizer, we'll call `run_classifier.convert_examples_to_features` on our InputExamples to convert them into features BERT understands."]},{"cell_type":"code","metadata":{"id":"LL5W8gEGRTAf","colab_type":"code","outputId":"ac320299-d0af-4bfd-aec9-ed5d51554823","executionInfo":{"status":"ok","timestamp":1572927388233,"user_tz":480,"elapsed":235008,"user":{"displayName":"Divya Sudhakar","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBAEe8lSbL-gO8W2QGjfXvHbFVw-wl2B28bQD3_6_A=s64","userId":"13661723492181317645"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# We'll set sequences to be at most 128 tokens long.\n","MAX_SEQ_LENGTH = 128\n","# Convert our train and test features to InputFeatures that BERT understands.\n","train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","dev_features = bert.run_classifier.convert_examples_to_features(dev_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 20000\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 20000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] burning questions about meg ##han mark ##le and prince harry ' s royal wedding ##t ##wo months to go before britain ’ s prince harry transforms his american sweetheart into a bride and a full - fledged member of the royal family . the venue has long been booked , but just who will be entering the doors of st . george ’ s chapel to witness the mat ##rim ##ony ? who will make the cut on the guest list ? what role will two future kings — harry ’ s brother , prince william , and his nephew , prince george — play in the ceremony ? and what will the world call mark ##le after she formally becomes royalty ? prince harry and [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] burning questions about meg ##han mark ##le and prince harry ' s royal wedding ##t ##wo months to go before britain ’ s prince harry transforms his american sweetheart into a bride and a full - fledged member of the royal family . the venue has long been booked , but just who will be entering the doors of st . george ’ s chapel to witness the mat ##rim ##ony ? who will make the cut on the guest list ? what role will two future kings — harry ’ s brother , prince william , and his nephew , prince george — play in the ceremony ? and what will the world call mark ##le after she formally becomes royalty ? prince harry and [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 5255 3980 2055 12669 4819 2928 2571 1998 3159 4302 1005 1055 2548 5030 2102 12155 2706 2000 2175 2077 3725 1521 1055 3159 4302 21743 2010 2137 12074 2046 1037 8959 1998 1037 2440 1011 26712 2266 1997 1996 2548 2155 1012 1996 6891 2038 2146 2042 17414 1010 2021 2074 2040 2097 2022 5738 1996 4303 1997 2358 1012 2577 1521 1055 4970 2000 7409 1996 13523 20026 16585 1029 2040 2097 2191 1996 3013 2006 1996 4113 2862 1029 2054 2535 2097 2048 2925 5465 1517 4302 1521 1055 2567 1010 3159 2520 1010 1998 2010 7833 1010 3159 2577 1517 2377 1999 1996 5103 1029 1998 2054 2097 1996 2088 2655 2928 2571 2044 2016 6246 4150 16664 1029 3159 4302 1998 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 5255 3980 2055 12669 4819 2928 2571 1998 3159 4302 1005 1055 2548 5030 2102 12155 2706 2000 2175 2077 3725 1521 1055 3159 4302 21743 2010 2137 12074 2046 1037 8959 1998 1037 2440 1011 26712 2266 1997 1996 2548 2155 1012 1996 6891 2038 2146 2042 17414 1010 2021 2074 2040 2097 2022 5738 1996 4303 1997 2358 1012 2577 1521 1055 4970 2000 7409 1996 13523 20026 16585 1029 2040 2097 2191 1996 3013 2006 1996 4113 2862 1029 2054 2535 2097 2048 2925 5465 1517 4302 1521 1055 2567 1010 3159 2520 1010 1998 2010 7833 1010 3159 2577 1517 2377 1999 1996 5103 1029 1998 2054 2097 1996 2088 2655 2928 2571 2044 2016 6246 4150 16664 1029 3159 4302 1998 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] aaron paul says his baby girl is due ' any minute now ' aaron paul can ’ t wait to meet his baby girl ! the path star , 38 , is looking forward to being a father and he shared how he and pregnant wife lauren are preparing to become first - time parents . during an appearance on jimmy kim ##mel live ! on tuesday , paul shared that lauren , 31 , is due “ any minute now ” and that the couple has been counting down to meet their first child . “ i ’ m over the moon excited , ” the actor told late - night host jimmy kim ##mel , adding , “ i love babies , i ’ [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] aaron paul says his baby girl is due ' any minute now ' aaron paul can ’ t wait to meet his baby girl ! the path star , 38 , is looking forward to being a father and he shared how he and pregnant wife lauren are preparing to become first - time parents . during an appearance on jimmy kim ##mel live ! on tuesday , paul shared that lauren , 31 , is due “ any minute now ” and that the couple has been counting down to meet their first child . “ i ’ m over the moon excited , ” the actor told late - night host jimmy kim ##mel , adding , “ i love babies , i ’ [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 7158 2703 2758 2010 3336 2611 2003 2349 1005 2151 3371 2085 1005 7158 2703 2064 1521 1056 3524 2000 3113 2010 3336 2611 999 1996 4130 2732 1010 4229 1010 2003 2559 2830 2000 2108 1037 2269 1998 2002 4207 2129 2002 1998 6875 2564 10294 2024 8225 2000 2468 2034 1011 2051 3008 1012 2076 2019 3311 2006 5261 5035 10199 2444 999 2006 9857 1010 2703 4207 2008 10294 1010 2861 1010 2003 2349 1523 2151 3371 2085 1524 1998 2008 1996 3232 2038 2042 10320 2091 2000 3113 2037 2034 2775 1012 1523 1045 1521 1049 2058 1996 4231 7568 1010 1524 1996 3364 2409 2397 1011 2305 3677 5261 5035 10199 1010 5815 1010 1523 1045 2293 10834 1010 1045 1521 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 7158 2703 2758 2010 3336 2611 2003 2349 1005 2151 3371 2085 1005 7158 2703 2064 1521 1056 3524 2000 3113 2010 3336 2611 999 1996 4130 2732 1010 4229 1010 2003 2559 2830 2000 2108 1037 2269 1998 2002 4207 2129 2002 1998 6875 2564 10294 2024 8225 2000 2468 2034 1011 2051 3008 1012 2076 2019 3311 2006 5261 5035 10199 2444 999 2006 9857 1010 2703 4207 2008 10294 1010 2861 1010 2003 2349 1523 2151 3371 2085 1524 1998 2008 1996 3232 2038 2042 10320 2091 2000 3113 2037 2034 2775 1012 1523 1045 1521 1049 2058 1996 4231 7568 1010 1524 1996 3364 2409 2397 1011 2305 3677 5261 5035 10199 1010 5815 1010 1523 1045 2293 10834 1010 1045 1521 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] can drake stop trying to control women ’ s sexuality ? with the impending release of his fifth studio album — the first since the four - time platinum , grammy - nominated 2016 views — drake has many questions surrounding him . can he again move a million units in a week ? can he prove all the doubt ##ers wrong after two years of ghost ##writing allegations ? can he top “ hot ##line b ##ling ” or “ one dance ” ? can more life over ##take take care as drake ’ s undo ##ub ##ted classic album ? but also , can he , like so many artists in 2016 — beyonce ( lemon ##ade ) , sol ##ange ( a seat [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] can drake stop trying to control women ’ s sexuality ? with the impending release of his fifth studio album — the first since the four - time platinum , grammy - nominated 2016 views — drake has many questions surrounding him . can he again move a million units in a week ? can he prove all the doubt ##ers wrong after two years of ghost ##writing allegations ? can he top “ hot ##line b ##ling ” or “ one dance ” ? can more life over ##take take care as drake ’ s undo ##ub ##ted classic album ? but also , can he , like so many artists in 2016 — beyonce ( lemon ##ade ) , sol ##ange ( a seat [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2064 7867 2644 2667 2000 2491 2308 1521 1055 13798 1029 2007 1996 17945 2713 1997 2010 3587 2996 2201 1517 1996 2034 2144 1996 2176 1011 2051 8899 1010 8922 1011 4222 2355 5328 1517 7867 2038 2116 3980 4193 2032 1012 2064 2002 2153 2693 1037 2454 3197 1999 1037 2733 1029 2064 2002 6011 2035 1996 4797 2545 3308 2044 2048 2086 1997 5745 18560 9989 1029 2064 2002 2327 1523 2980 4179 1038 2989 1524 2030 1523 2028 3153 1524 1029 2064 2062 2166 2058 15166 2202 2729 2004 7867 1521 1055 25672 12083 3064 4438 2201 1029 2021 2036 1010 2064 2002 1010 2066 2061 2116 3324 1999 2355 1517 20773 1006 14380 9648 1007 1010 14017 22043 1006 1037 2835 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2064 7867 2644 2667 2000 2491 2308 1521 1055 13798 1029 2007 1996 17945 2713 1997 2010 3587 2996 2201 1517 1996 2034 2144 1996 2176 1011 2051 8899 1010 8922 1011 4222 2355 5328 1517 7867 2038 2116 3980 4193 2032 1012 2064 2002 2153 2693 1037 2454 3197 1999 1037 2733 1029 2064 2002 6011 2035 1996 4797 2545 3308 2044 2048 2086 1997 5745 18560 9989 1029 2064 2002 2327 1523 2980 4179 1038 2989 1524 2030 1523 2028 3153 1524 1029 2064 2062 2166 2058 15166 2202 2729 2004 7867 1521 1055 25672 12083 3064 4438 2201 1029 2021 2036 1010 2064 2002 1010 2066 2061 2116 3324 1999 2355 1517 20773 1006 14380 9648 1007 1010 14017 22043 1006 1037 2835 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] miss usa 2017 : see all 51 contestants in their swim ##suit ##s and evening gown ##s before the winner is crowned ##sho ##w - mandal ##ay - resort - casino - las ( excerpt ) read more at : e ! online wake up to breaking news ! submit bust out the swim ##wear and designer dresses : there ' s a beauty pageant headed into town . we ' re just days after from the miss usa 2017 competition and e ! news has your first look at the 51 contestants competing for the very special crown . before the show goes live at the mandal ##ay resort and casino in las vegas sunday night , some of the ladies are sharing their secrets [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] miss usa 2017 : see all 51 contestants in their swim ##suit ##s and evening gown ##s before the winner is crowned ##sho ##w - mandal ##ay - resort - casino - las ( excerpt ) read more at : e ! online wake up to breaking news ! submit bust out the swim ##wear and designer dresses : there ' s a beauty pageant headed into town . we ' re just days after from the miss usa 2017 competition and e ! news has your first look at the 51 contestants competing for the very special crown . before the show goes live at the mandal ##ay resort and casino in las vegas sunday night , some of the ladies are sharing their secrets [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 3335 3915 2418 1024 2156 2035 4868 10584 1999 2037 9880 28880 2015 1998 3944 11739 2015 2077 1996 3453 2003 10249 22231 2860 1011 24373 4710 1011 7001 1011 9270 1011 5869 1006 28142 1007 3191 2062 2012 1024 1041 999 3784 5256 2039 2000 4911 2739 999 12040 13950 2041 1996 9880 16689 1998 5859 14464 1024 2045 1005 1055 1037 5053 12438 3753 2046 2237 1012 2057 1005 2128 2074 2420 2044 2013 1996 3335 3915 2418 2971 1998 1041 999 2739 2038 2115 2034 2298 2012 1996 4868 10584 6637 2005 1996 2200 2569 4410 1012 2077 1996 2265 3632 2444 2012 1996 24373 4710 7001 1998 9270 1999 5869 7136 4465 2305 1010 2070 1997 1996 6456 2024 6631 2037 7800 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 3335 3915 2418 1024 2156 2035 4868 10584 1999 2037 9880 28880 2015 1998 3944 11739 2015 2077 1996 3453 2003 10249 22231 2860 1011 24373 4710 1011 7001 1011 9270 1011 5869 1006 28142 1007 3191 2062 2012 1024 1041 999 3784 5256 2039 2000 4911 2739 999 12040 13950 2041 1996 9880 16689 1998 5859 14464 1024 2045 1005 1055 1037 5053 12438 3753 2046 2237 1012 2057 1005 2128 2074 2420 2044 2013 1996 3335 3915 2418 2971 1998 1041 999 2739 2038 2115 2034 2298 2012 1996 4868 10584 6637 2005 1996 2200 2569 4410 1012 2077 1996 2265 3632 2444 2012 1996 24373 4710 7001 1998 9270 1999 5869 7136 4465 2305 1010 2070 1997 1996 6456 2024 6631 2037 7800 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] inside david foster & katharine mc ##ph ##ee ' s ' staged ' romance ##kat ##hri ##ne mc ##ph ##ee and record executive david foster were and record executive ##wer ##e spotted on another date last night — leaving a \" romantic \" dinner at craig ' s restaurant in west hollywood , cal ##if . after several pd ##a - filled public outing ##s , a source close to the 67 - year - old music mo ##gul told radar ##on ##line . com exclusively that the bud ##ding romance is all for show ! click through seven love ##y - dove ##y photos to find out the truth behind why the unlikely duo is really dating ! according to the source , \" david [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] inside david foster & katharine mc ##ph ##ee ' s ' staged ' romance ##kat ##hri ##ne mc ##ph ##ee and record executive david foster were and record executive ##wer ##e spotted on another date last night — leaving a \" romantic \" dinner at craig ' s restaurant in west hollywood , cal ##if . after several pd ##a - filled public outing ##s , a source close to the 67 - year - old music mo ##gul told radar ##on ##line . com exclusively that the bud ##ding romance is all for show ! click through seven love ##y - dove ##y photos to find out the truth behind why the unlikely duo is really dating ! according to the source , \" david [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2503 2585 6469 1004 25739 11338 8458 4402 1005 1055 1005 9813 1005 7472 24498 26378 2638 11338 8458 4402 1998 2501 3237 2585 6469 2020 1998 2501 3237 13777 2063 7282 2006 2178 3058 2197 2305 1517 2975 1037 1000 6298 1000 4596 2012 7010 1005 1055 4825 1999 2225 5365 1010 10250 10128 1012 2044 2195 22851 2050 1011 3561 2270 26256 2015 1010 1037 3120 2485 2000 1996 6163 1011 2095 1011 2214 2189 9587 24848 2409 7217 2239 4179 1012 4012 7580 2008 1996 13007 4667 7472 2003 2035 2005 2265 999 11562 2083 2698 2293 2100 1011 10855 2100 7760 2000 2424 2041 1996 3606 2369 2339 1996 9832 6829 2003 2428 5306 999 2429 2000 1996 3120 1010 1000 2585 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2503 2585 6469 1004 25739 11338 8458 4402 1005 1055 1005 9813 1005 7472 24498 26378 2638 11338 8458 4402 1998 2501 3237 2585 6469 2020 1998 2501 3237 13777 2063 7282 2006 2178 3058 2197 2305 1517 2975 1037 1000 6298 1000 4596 2012 7010 1005 1055 4825 1999 2225 5365 1010 10250 10128 1012 2044 2195 22851 2050 1011 3561 2270 26256 2015 1010 1037 3120 2485 2000 1996 6163 1011 2095 1011 2214 2189 9587 24848 2409 7217 2239 4179 1012 4012 7580 2008 1996 13007 4667 7472 2003 2035 2005 2265 999 11562 2083 2698 2293 2100 1011 10855 2100 7760 2000 2424 2041 1996 3606 2369 2339 1996 9832 6829 2003 2428 5306 999 2429 2000 1996 3120 1010 1000 2585 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: True (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: True (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 10000 of 20000\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 10000 of 20000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 1000\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 1000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] megan fox shares rare photo of son journey river green ! megan fox does not often share photos of her kids , but she just shared a pic of her youngest son journey river green . earlier this weekend , the 32 - year - old actress shared the photo of her youngest son , who was born in 2016 . photos : check out the latest pic ##s of megan fox megan and brian austin green have two other sons , 5 - year - old noah and 4 - year - old bo ##dhi . megan posted the photo on her ins ##tagram account and capt ##ioned the photo with , “ mood . ” see the adorable photo from megan ’ s ins [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] megan fox shares rare photo of son journey river green ! megan fox does not often share photos of her kids , but she just shared a pic of her youngest son journey river green . earlier this weekend , the 32 - year - old actress shared the photo of her youngest son , who was born in 2016 . photos : check out the latest pic ##s of megan fox megan and brian austin green have two other sons , 5 - year - old noah and 4 - year - old bo ##dhi . megan posted the photo on her ins ##tagram account and capt ##ioned the photo with , “ mood . ” see the adorable photo from megan ’ s ins [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 12756 4419 6661 4678 6302 1997 2365 4990 2314 2665 999 12756 4419 2515 2025 2411 3745 7760 1997 2014 4268 1010 2021 2016 2074 4207 1037 27263 1997 2014 6587 2365 4990 2314 2665 1012 3041 2023 5353 1010 1996 3590 1011 2095 1011 2214 3883 4207 1996 6302 1997 2014 6587 2365 1010 2040 2001 2141 1999 2355 1012 7760 1024 4638 2041 1996 6745 27263 2015 1997 12756 4419 12756 1998 4422 5899 2665 2031 2048 2060 4124 1010 1019 1011 2095 1011 2214 7240 1998 1018 1011 2095 1011 2214 8945 19114 1012 12756 6866 1996 6302 2006 2014 16021 23091 4070 1998 14408 19798 1996 6302 2007 1010 1523 6888 1012 1524 2156 1996 23677 6302 2013 12756 1521 1055 16021 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 12756 4419 6661 4678 6302 1997 2365 4990 2314 2665 999 12756 4419 2515 2025 2411 3745 7760 1997 2014 4268 1010 2021 2016 2074 4207 1037 27263 1997 2014 6587 2365 4990 2314 2665 1012 3041 2023 5353 1010 1996 3590 1011 2095 1011 2214 3883 4207 1996 6302 1997 2014 6587 2365 1010 2040 2001 2141 1999 2355 1012 7760 1024 4638 2041 1996 6745 27263 2015 1997 12756 4419 12756 1998 4422 5899 2665 2031 2048 2060 4124 1010 1019 1011 2095 1011 2214 7240 1998 1018 1011 2095 1011 2214 8945 19114 1012 12756 6866 1996 6302 2006 2014 16021 23091 4070 1998 14408 19798 1996 6302 2007 1010 1523 6888 1012 1524 2156 1996 23677 6302 2013 12756 1521 1055 16021 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] katy perry forgive ##s taylor swift and adds & amp ; quo ##t ; i ’ m sorry for anything i ever did & amp ; quo ##t ; katy perry forgive ##s taylor swift and adds , \" i ’ m sorry for anything i ever did \" feud over soon ? katy perry has extended an olive branch to taylor swift . in a live interview with aria ##na huffington on her the thrive global podcast saturday , perry was asked if she would … http : / / if ##t . tt / 2 ##rf ##ib ##bo [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] katy perry forgive ##s taylor swift and adds & amp ; quo ##t ; i ’ m sorry for anything i ever did & amp ; quo ##t ; katy perry forgive ##s taylor swift and adds , \" i ’ m sorry for anything i ever did \" feud over soon ? katy perry has extended an olive branch to taylor swift . in a live interview with aria ##na huffington on her the thrive global podcast saturday , perry was asked if she would … http : / / if ##t . tt / 2 ##rf ##ib ##bo [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 17870 6890 9641 2015 4202 9170 1998 9909 1004 23713 1025 22035 2102 1025 1045 1521 1049 3374 2005 2505 1045 2412 2106 1004 23713 1025 22035 2102 1025 17870 6890 9641 2015 4202 9170 1998 9909 1010 1000 1045 1521 1049 3374 2005 2505 1045 2412 2106 1000 13552 2058 2574 1029 17870 6890 2038 3668 2019 9724 3589 2000 4202 9170 1012 1999 1037 2444 4357 2007 9342 2532 26149 2006 2014 1996 25220 3795 16110 5095 1010 6890 2001 2356 2065 2016 2052 1529 8299 1024 1013 1013 2065 2102 1012 23746 1013 1016 12881 12322 5092 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 17870 6890 9641 2015 4202 9170 1998 9909 1004 23713 1025 22035 2102 1025 1045 1521 1049 3374 2005 2505 1045 2412 2106 1004 23713 1025 22035 2102 1025 17870 6890 9641 2015 4202 9170 1998 9909 1010 1000 1045 1521 1049 3374 2005 2505 1045 2412 2106 1000 13552 2058 2574 1029 17870 6890 2038 3668 2019 9724 3589 2000 4202 9170 1012 1999 1037 2444 4357 2007 9342 2532 26149 2006 2014 1996 25220 3795 16110 5095 1010 6890 2001 2356 2065 2016 2052 1529 8299 1024 1013 1013 2065 2102 1012 23746 1013 1016 12881 12322 5092 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] ya ##ra shah ##idi says the fanny pack is a millennia ##l must - have ##just in : the fanny pack , also known as a belt bag , has made a comeback . in skinny jeans , a pu ##ma graphic print wind ##breaker and sued ##e bow sneakers , ya ##ra shah ##idi placed a bright yellow fanny . . . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] ya ##ra shah ##idi says the fanny pack is a millennia ##l must - have ##just in : the fanny pack , also known as a belt bag , has made a comeback . in skinny jeans , a pu ##ma graphic print wind ##breaker and sued ##e bow sneakers , ya ##ra shah ##idi placed a bright yellow fanny . . . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 8038 2527 7890 28173 2758 1996 17813 5308 2003 1037 27620 2140 2442 1011 2031 29427 1999 1024 1996 17813 5308 1010 2036 2124 2004 1037 5583 4524 1010 2038 2081 1037 12845 1012 1999 15629 6312 1010 1037 16405 2863 8425 6140 3612 21204 1998 12923 2063 6812 28130 1010 8038 2527 7890 28173 2872 1037 4408 3756 17813 1012 1012 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 8038 2527 7890 28173 2758 1996 17813 5308 2003 1037 27620 2140 2442 1011 2031 29427 1999 1024 1996 17813 5308 1010 2036 2124 2004 1037 5583 4524 1010 2038 2081 1037 12845 1012 1999 15629 6312 1010 1037 16405 2863 8425 6140 3612 21204 1998 12923 2063 6812 28130 1010 8038 2527 7890 28173 2872 1037 4408 3756 17813 1012 1012 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] is cai ##tly ##n jen ##ner dating someone ; fake story of affair of cai ##tly ##n jen ##ner and boxer yu ##sa ##f mack , scroll to read the spicy story of these two – married biography ##is cai ##tly ##n jen ##ner dating someone ; fake story of affair of cai ##tly ##n jen ##ner and boxer yu ##sa ##f mack , scroll to read the spicy story of these two share this generally , after the gender change probably people are quite interested in the personal life of cai ##tly ##n jen ##ner . no doubt , much more in her love life . the question which is hitting and rolling through the head of all the fans are like : is she [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] is cai ##tly ##n jen ##ner dating someone ; fake story of affair of cai ##tly ##n jen ##ner and boxer yu ##sa ##f mack , scroll to read the spicy story of these two – married biography ##is cai ##tly ##n jen ##ner dating someone ; fake story of affair of cai ##tly ##n jen ##ner and boxer yu ##sa ##f mack , scroll to read the spicy story of these two share this generally , after the gender change probably people are quite interested in the personal life of cai ##tly ##n jen ##ner . no doubt , much more in her love life . the question which is hitting and rolling through the head of all the fans are like : is she [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2003 29080 14626 2078 15419 3678 5306 2619 1025 8275 2466 1997 6771 1997 29080 14626 2078 15419 3678 1998 10423 9805 3736 2546 11349 1010 17186 2000 3191 1996 25482 2466 1997 2122 2048 1516 2496 8308 2483 29080 14626 2078 15419 3678 5306 2619 1025 8275 2466 1997 6771 1997 29080 14626 2078 15419 3678 1998 10423 9805 3736 2546 11349 1010 17186 2000 3191 1996 25482 2466 1997 2122 2048 3745 2023 3227 1010 2044 1996 5907 2689 2763 2111 2024 3243 4699 1999 1996 3167 2166 1997 29080 14626 2078 15419 3678 1012 2053 4797 1010 2172 2062 1999 2014 2293 2166 1012 1996 3160 2029 2003 7294 1998 5291 2083 1996 2132 1997 2035 1996 4599 2024 2066 1024 2003 2016 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2003 29080 14626 2078 15419 3678 5306 2619 1025 8275 2466 1997 6771 1997 29080 14626 2078 15419 3678 1998 10423 9805 3736 2546 11349 1010 17186 2000 3191 1996 25482 2466 1997 2122 2048 1516 2496 8308 2483 29080 14626 2078 15419 3678 5306 2619 1025 8275 2466 1997 6771 1997 29080 14626 2078 15419 3678 1998 10423 9805 3736 2546 11349 1010 17186 2000 3191 1996 25482 2466 1997 2122 2048 3745 2023 3227 1010 2044 1996 5907 2689 2763 2111 2024 3243 4699 1999 1996 3167 2166 1997 29080 14626 2078 15419 3678 1012 2053 4797 1010 2172 2062 1999 2014 2293 2166 1012 1996 3160 2029 2003 7294 1998 5291 2083 1996 2132 1997 2035 1996 4599 2024 2066 1024 2003 2016 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: True (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: True (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] this is the best keeping up with the ka ##rda ##shi ##ans moment ever , according to ka ##rds bf ##fs malik ##a ha ##q ##q & simon hu ##ck on ka ##rda ##shi ##ans ##ab ##out trend ##oli ##zer ##™ trend ##oli ##zer ##™ ( patent pending ) automatically scans the internet for trend ##ing content . the website you are looking at has no human editors at all : links to trend ##ing stories are automatically posted from a selection of the data trend ##oli ##zer ##™ picked up . if you are interested in using the trend ##oli ##zer ##™ engine , dashboard or api for your own projects , more information is available at get . trend ##oli ##zer . com . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] this is the best keeping up with the ka ##rda ##shi ##ans moment ever , according to ka ##rds bf ##fs malik ##a ha ##q ##q & simon hu ##ck on ka ##rda ##shi ##ans ##ab ##out trend ##oli ##zer ##™ trend ##oli ##zer ##™ ( patent pending ) automatically scans the internet for trend ##ing content . the website you are looking at has no human editors at all : links to trend ##ing stories are automatically posted from a selection of the data trend ##oli ##zer ##™ picked up . if you are interested in using the trend ##oli ##zer ##™ engine , dashboard or api for your own projects , more information is available at get . trend ##oli ##zer . com . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2023 2003 1996 2190 4363 2039 2007 1996 10556 13639 6182 6962 2617 2412 1010 2429 2000 10556 17811 28939 10343 14360 2050 5292 4160 4160 1004 4079 15876 3600 2006 10556 13639 6182 6962 7875 5833 9874 10893 6290 30108 9874 10893 6290 30108 1006 7353 14223 1007 8073 27404 1996 4274 2005 9874 2075 4180 1012 1996 4037 2017 2024 2559 2012 2038 2053 2529 10195 2012 2035 1024 6971 2000 9874 2075 3441 2024 8073 6866 2013 1037 4989 1997 1996 2951 9874 10893 6290 30108 3856 2039 1012 2065 2017 2024 4699 1999 2478 1996 9874 10893 6290 30108 3194 1010 24923 2030 17928 2005 2115 2219 3934 1010 2062 2592 2003 2800 2012 2131 1012 9874 10893 6290 1012 4012 1012 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2023 2003 1996 2190 4363 2039 2007 1996 10556 13639 6182 6962 2617 2412 1010 2429 2000 10556 17811 28939 10343 14360 2050 5292 4160 4160 1004 4079 15876 3600 2006 10556 13639 6182 6962 7875 5833 9874 10893 6290 30108 9874 10893 6290 30108 1006 7353 14223 1007 8073 27404 1996 4274 2005 9874 2075 4180 1012 1996 4037 2017 2024 2559 2012 2038 2053 2529 10195 2012 2035 1024 6971 2000 9874 2075 3441 2024 8073 6866 2013 1037 4989 1997 1996 2951 9874 10893 6290 30108 3856 2039 1012 2065 2017 2024 4699 1999 2478 1996 9874 10893 6290 30108 3194 1010 24923 2030 17928 2005 2115 2219 3934 1010 2062 2592 2003 2800 2012 2131 1012 9874 10893 6290 1012 4012 1012 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 1231\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 1231\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] hometown visit from hell ? one ‘ bachelor ##ette ’ contestant ’ s mom threatens rachel lindsay ##se ##cu ##rity ! on the new episode of the bachelor ##ette , it seems like rachel lindsay finds out exactly why this seasons front ##runner bryan aba ##sol ##o ’ s last relationship didn ’ t last – his mother ! the bachelor ##ette ‘ s airing of hometown dates is just days away and monday night ’ s episode looks like it will definitely be one for the books as rachel meets bryan , dean , eric and peter ’ s families . while dean seemed to be the most nervous about rachel meeting his family , judging from the upcoming episode ’ s newest promo , [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] hometown visit from hell ? one ‘ bachelor ##ette ’ contestant ’ s mom threatens rachel lindsay ##se ##cu ##rity ! on the new episode of the bachelor ##ette , it seems like rachel lindsay finds out exactly why this seasons front ##runner bryan aba ##sol ##o ’ s last relationship didn ’ t last – his mother ! the bachelor ##ette ‘ s airing of hometown dates is just days away and monday night ’ s episode looks like it will definitely be one for the books as rachel meets bryan , dean , eric and peter ’ s families . while dean seemed to be the most nervous about rachel meeting his family , judging from the upcoming episode ’ s newest promo , [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 9627 3942 2013 3109 1029 2028 1520 5065 7585 1521 10832 1521 1055 3566 17016 5586 12110 3366 10841 15780 999 2006 1996 2047 2792 1997 1996 5065 7585 1010 2009 3849 2066 5586 12110 4858 2041 3599 2339 2023 3692 2392 23195 8527 19557 19454 2080 1521 1055 2197 3276 2134 1521 1056 2197 1516 2010 2388 999 1996 5065 7585 1520 1055 10499 1997 9627 5246 2003 2074 2420 2185 1998 6928 2305 1521 1055 2792 3504 2066 2009 2097 5791 2022 2028 2005 1996 2808 2004 5586 6010 8527 1010 4670 1010 4388 1998 2848 1521 1055 2945 1012 2096 4670 2790 2000 2022 1996 2087 6091 2055 5586 3116 2010 2155 1010 13325 2013 1996 9046 2792 1521 1055 14751 19430 1010 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 9627 3942 2013 3109 1029 2028 1520 5065 7585 1521 10832 1521 1055 3566 17016 5586 12110 3366 10841 15780 999 2006 1996 2047 2792 1997 1996 5065 7585 1010 2009 3849 2066 5586 12110 4858 2041 3599 2339 2023 3692 2392 23195 8527 19557 19454 2080 1521 1055 2197 3276 2134 1521 1056 2197 1516 2010 2388 999 1996 5065 7585 1520 1055 10499 1997 9627 5246 2003 2074 2420 2185 1998 6928 2305 1521 1055 2792 3504 2066 2009 2097 5791 2022 2028 2005 1996 2808 2004 5586 6010 8527 1010 4670 1010 4388 1998 2848 1521 1055 2945 1012 2096 4670 2790 2000 2022 1996 2087 6091 2055 5586 3116 2010 2155 1010 13325 2013 1996 9046 2792 1521 1055 14751 19430 1010 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] e ! news exclusive : la ' my ##ia good panic ##s over photos ##hoot with eric bell ##inger on the platinum life : \" i gotta get my s - - t together ! \" [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] e ! news exclusive : la ' my ##ia good panic ##s over photos ##hoot with eric bell ##inger on the platinum life : \" i gotta get my s - - t together ! \" [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1041 999 2739 7262 1024 2474 1005 2026 2401 2204 6634 2015 2058 7760 23416 2007 4388 4330 9912 2006 1996 8899 2166 1024 1000 1045 10657 2131 2026 1055 1011 1011 1056 2362 999 1000 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1041 999 2739 7262 1024 2474 1005 2026 2401 2204 6634 2015 2058 7760 23416 2007 4388 4330 9912 2006 1996 8899 2166 1024 1000 1045 10657 2131 2026 1055 1011 1011 1056 2362 999 1000 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] tv ' s top couple 2018 : vote in the sweet 16 now ! river ##dale - out ##lander - sense ##8 - super ##girl - competitors ( excerpt ) read more at : e ! online wake up to breaking news ! submit let the battles continue ! tv ' s top couple 2018 has officially reached the sweet 16 , meaning there are eight fights to be fought over the next two days , and there are some pretty serious match - ups in this round . will river ##dale , out ##lander , sense ##8 , and super ##girl all continue with two competitors each ? . . . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] tv ' s top couple 2018 : vote in the sweet 16 now ! river ##dale - out ##lander - sense ##8 - super ##girl - competitors ( excerpt ) read more at : e ! online wake up to breaking news ! submit let the battles continue ! tv ' s top couple 2018 has officially reached the sweet 16 , meaning there are eight fights to be fought over the next two days , and there are some pretty serious match - ups in this round . will river ##dale , out ##lander , sense ##8 , and super ##girl all continue with two competitors each ? . . . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2694 1005 1055 2327 3232 2760 1024 3789 1999 1996 4086 2385 2085 999 2314 5634 1011 2041 22691 1011 3168 2620 1011 3565 15239 1011 10159 1006 28142 1007 3191 2062 2012 1024 1041 999 3784 5256 2039 2000 4911 2739 999 12040 2292 1996 7465 3613 999 2694 1005 1055 2327 3232 2760 2038 3985 2584 1996 4086 2385 1010 3574 2045 2024 2809 9590 2000 2022 4061 2058 1996 2279 2048 2420 1010 1998 2045 2024 2070 3492 3809 2674 1011 11139 1999 2023 2461 1012 2097 2314 5634 1010 2041 22691 1010 3168 2620 1010 1998 3565 15239 2035 3613 2007 2048 10159 2169 1029 1012 1012 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2694 1005 1055 2327 3232 2760 1024 3789 1999 1996 4086 2385 2085 999 2314 5634 1011 2041 22691 1011 3168 2620 1011 3565 15239 1011 10159 1006 28142 1007 3191 2062 2012 1024 1041 999 3784 5256 2039 2000 4911 2739 999 12040 2292 1996 7465 3613 999 2694 1005 1055 2327 3232 2760 2038 3985 2584 1996 4086 2385 1010 3574 2045 2024 2809 9590 2000 2022 4061 2058 1996 2279 2048 2420 1010 1998 2045 2024 2070 3492 3809 2674 1011 11139 1999 2023 2461 1012 2097 2314 5634 1010 2041 22691 1010 3168 2620 1010 1998 3565 15239 2035 3613 2007 2048 10159 2169 1029 1012 1012 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] sophie turner ’ s engagement rings ##op ##hi ##e turner ’ s engagement ring is definitely fit for a queen . the young game of throne ##s star ##let prepares to join house jonas , and took to ins ##tagram to spread the word . sophie and fiance joe jonas raced each other to social media , posting the same sweet photo of their two hands , with sophie sporting a dazzling diamond engagement ring . the bride - to - be capt ##ioned the pic with , “ i said yes , ” , while jonas echoed the sentiment , writing , “ she said yes ! ” the stars ##tr ##uck couple was first introduced in 2016 by mutual friend hail ##ee stein ##feld [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] sophie turner ’ s engagement rings ##op ##hi ##e turner ’ s engagement ring is definitely fit for a queen . the young game of throne ##s star ##let prepares to join house jonas , and took to ins ##tagram to spread the word . sophie and fiance joe jonas raced each other to social media , posting the same sweet photo of their two hands , with sophie sporting a dazzling diamond engagement ring . the bride - to - be capt ##ioned the pic with , “ i said yes , ” , while jonas echoed the sentiment , writing , “ she said yes ! ” the stars ##tr ##uck couple was first introduced in 2016 by mutual friend hail ##ee stein ##feld [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 8234 6769 1521 1055 8147 7635 7361 4048 2063 6769 1521 1055 8147 3614 2003 5791 4906 2005 1037 3035 1012 1996 2402 2208 1997 6106 2015 2732 7485 20776 2000 3693 2160 10680 1010 1998 2165 2000 16021 23091 2000 3659 1996 2773 1012 8234 1998 19154 3533 10680 8255 2169 2060 2000 2591 2865 1010 14739 1996 2168 4086 6302 1997 2037 2048 2398 1010 2007 8234 7419 1037 28190 6323 8147 3614 1012 1996 8959 1011 2000 1011 2022 14408 19798 1996 27263 2007 1010 1523 1045 2056 2748 1010 1524 1010 2096 10680 10187 1996 15792 1010 3015 1010 1523 2016 2056 2748 999 1524 1996 3340 16344 12722 3232 2001 2034 3107 1999 2355 2011 8203 2767 16889 4402 14233 8151 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 8234 6769 1521 1055 8147 7635 7361 4048 2063 6769 1521 1055 8147 3614 2003 5791 4906 2005 1037 3035 1012 1996 2402 2208 1997 6106 2015 2732 7485 20776 2000 3693 2160 10680 1010 1998 2165 2000 16021 23091 2000 3659 1996 2773 1012 8234 1998 19154 3533 10680 8255 2169 2060 2000 2591 2865 1010 14739 1996 2168 4086 6302 1997 2037 2048 2398 1010 2007 8234 7419 1037 28190 6323 8147 3614 1012 1996 8959 1011 2000 1011 2022 14408 19798 1996 27263 2007 1010 1523 1045 2056 2748 1010 1524 1010 2096 10680 10187 1996 15792 1010 3015 1010 1523 2016 2056 2748 999 1524 1996 3340 16344 12722 3232 2001 2034 3107 1999 2355 2011 8203 2767 16889 4402 14233 8151 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] ' game of throne ##s ' episode 4 leaks online , but the hbo hack isn ' t to blame ##h ##bo hbo has been scrambling to figure out what exactly was pi ##lf ##ered in the massive 1 . 5 tb security breach late last month , and now they have a new headache on their hands . an early copy of this sunday ’ s game of throne ##s episode , the spoil ##s of war , has leaked online . but amazingly , according to the verge , the leak actually has nothing to do with the hack , and is instead the fault of a distribution partner who let the episode slip online . while the hacker ##s have published a script [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] ' game of throne ##s ' episode 4 leaks online , but the hbo hack isn ' t to blame ##h ##bo hbo has been scrambling to figure out what exactly was pi ##lf ##ered in the massive 1 . 5 tb security breach late last month , and now they have a new headache on their hands . an early copy of this sunday ’ s game of throne ##s episode , the spoil ##s of war , has leaked online . but amazingly , according to the verge , the leak actually has nothing to do with the hack , and is instead the fault of a distribution partner who let the episode slip online . while the hacker ##s have published a script [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1005 2208 1997 6106 2015 1005 2792 1018 29324 3784 1010 2021 1996 14633 20578 3475 1005 1056 2000 7499 2232 5092 14633 2038 2042 25240 2000 3275 2041 2054 3599 2001 14255 10270 6850 1999 1996 5294 1015 1012 1019 26419 3036 12510 2397 2197 3204 1010 1998 2085 2027 2031 1037 2047 14978 2006 2037 2398 1012 2019 2220 6100 1997 2023 4465 1521 1055 2208 1997 6106 2015 2792 1010 1996 27594 2015 1997 2162 1010 2038 15748 3784 1012 2021 29350 1010 2429 2000 1996 16079 1010 1996 17271 2941 2038 2498 2000 2079 2007 1996 20578 1010 1998 2003 2612 1996 6346 1997 1037 4353 4256 2040 2292 1996 2792 7540 3784 1012 2096 1996 23307 2015 2031 2405 1037 5896 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1005 2208 1997 6106 2015 1005 2792 1018 29324 3784 1010 2021 1996 14633 20578 3475 1005 1056 2000 7499 2232 5092 14633 2038 2042 25240 2000 3275 2041 2054 3599 2001 14255 10270 6850 1999 1996 5294 1015 1012 1019 26419 3036 12510 2397 2197 3204 1010 1998 2085 2027 2031 1037 2047 14978 2006 2037 2398 1012 2019 2220 6100 1997 2023 4465 1521 1055 2208 1997 6106 2015 2792 1010 1996 27594 2015 1997 2162 1010 2038 15748 3784 1012 2021 29350 1010 2429 2000 1996 16079 1010 1996 17271 2941 2038 2498 2000 2079 2007 1996 20578 1010 1998 2003 2612 1996 6346 1997 1037 4353 4256 2040 2292 1996 2792 7540 3784 1012 2096 1996 23307 2015 2031 2405 1037 5896 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: False (id = 1)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"ccp5trMwRtmr","colab_type":"text"},"source":["#Creating a model\n","\n","Now that we've prepared our data, let's focus on building a model. `create_model` does just this below. First, it loads the BERT tf hub module again (this time to extract the computation graph). Next, it creates a single new layer that will be trained to adapt BERT to our sentiment task (i.e. classifying whether a movie review is positive or negative). This strategy of using a mostly trained model is called [fine-tuning](http://wiki.fast.ai/index.php/Fine_tuning)."]},{"cell_type":"code","metadata":{"id":"6o2a5ZIvRcJq","colab_type":"code","colab":{}},"source":["def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n","                 num_labels):\n","  \"\"\"Creates a classification model.\"\"\"\n","\n","  bert_module = hub.Module(\n","      BERT_MODEL_HUB,\n","      trainable=True)\n","  bert_inputs = dict(\n","      input_ids=input_ids,\n","      input_mask=input_mask,\n","      segment_ids=segment_ids)\n","  bert_outputs = bert_module(\n","      inputs=bert_inputs,\n","      signature=\"tokens\",\n","      as_dict=True)\n","\n","  # Use \"pooled_output\" for classification tasks on an entire sentence.\n","  # Use \"sequence_outputs\" for token-level output.\n","  output_layer = bert_outputs[\"pooled_output\"]\n","\n","  hidden_size = output_layer.shape[-1].value\n","\n","  # Create our own layer to tune for politeness data.\n","  output_weights = tf.get_variable(\n","      \"output_weights\", [num_labels, hidden_size],\n","      initializer=tf.truncated_normal_initializer(stddev=0.02))\n","\n","  output_bias = tf.get_variable(\n","      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n","\n","  with tf.variable_scope(\"loss\"):\n","\n","    # Dropout helps prevent overfitting\n","    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n","\n","    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n","    logits = tf.nn.bias_add(logits, output_bias)\n","    log_probs = tf.nn.log_softmax(logits, axis=-1)\n","\n","    # Convert labels into one-hot encoding\n","    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n","\n","    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n","    # If we're predicting, we want predicted labels and the probabiltiies.\n","    if is_predicting:\n","      return (predicted_labels, log_probs)\n","\n","    # If we're train/eval, compute loss between predicted and actual label\n","    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n","    loss = tf.reduce_mean(per_example_loss)\n","    return (loss, predicted_labels, log_probs)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qpE0ZIDOCQzE","colab_type":"text"},"source":["Next we'll wrap our model function in a `model_fn_builder` function that adapts our model to work for training, evaluation, and prediction."]},{"cell_type":"code","metadata":{"id":"FnH-AnOQ9KKW","colab_type":"code","colab":{}},"source":["# model_fn_builder actually creates our model function\n","# using the passed parameters for num_labels, learning_rate, etc.\n","def model_fn_builder(num_labels, learning_rate, num_train_steps,\n","                     num_warmup_steps):\n","  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n","  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n","    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n","\n","    input_ids = features[\"input_ids\"]\n","    input_mask = features[\"input_mask\"]\n","    segment_ids = features[\"segment_ids\"]\n","    label_ids = features[\"label_ids\"]\n","\n","    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n","    \n","    # TRAIN and EVAL\n","    if not is_predicting:\n","\n","      (loss, predicted_labels, log_probs) = create_model(\n","        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","      train_op = bert.optimization.create_optimizer(\n","          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n","\n","      # Calculate evaluation metrics. \n","      def metric_fn(label_ids, predicted_labels):\n","        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n","        f1_score = tf.contrib.metrics.f1_score(\n","            label_ids,\n","            predicted_labels)\n","        auc = tf.metrics.auc(\n","            label_ids,\n","            predicted_labels)\n","        recall = tf.metrics.recall(\n","            label_ids,\n","            predicted_labels)\n","        precision = tf.metrics.precision(\n","            label_ids,\n","            predicted_labels) \n","        true_pos = tf.metrics.true_positives(\n","            label_ids,\n","            predicted_labels)\n","        true_neg = tf.metrics.true_negatives(\n","            label_ids,\n","            predicted_labels)   \n","        false_pos = tf.metrics.false_positives(\n","            label_ids,\n","            predicted_labels)  \n","        false_neg = tf.metrics.false_negatives(\n","            label_ids,\n","            predicted_labels)\n","        return {\n","            \"eval_accuracy\": accuracy,\n","            \"f1_score\": f1_score,\n","            \"auc\": auc,\n","            \"precision\": precision,\n","            \"recall\": recall,\n","            \"true_positives\": true_pos,\n","            \"true_negatives\": true_neg,\n","            \"false_positives\": false_pos,\n","            \"false_negatives\": false_neg,\n","        }\n","\n","      eval_metrics = metric_fn(label_ids, predicted_labels)\n","\n","      if mode == tf.estimator.ModeKeys.TRAIN:\n","        return tf.estimator.EstimatorSpec(mode=mode,\n","          loss=loss,\n","          train_op=train_op)\n","      else:\n","          return tf.estimator.EstimatorSpec(mode=mode,\n","            loss=loss,\n","            eval_metric_ops=eval_metrics)\n","    else:\n","      (predicted_labels, log_probs) = create_model(\n","        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","      predictions = {\n","          'probabilities': log_probs,\n","          'labels': predicted_labels\n","      }\n","      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n","\n","  # Return the actual model function in the closure\n","  return model_fn\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OjwJ4bTeWXD8","colab_type":"code","colab":{}},"source":["# Compute train and warmup steps from batch size\n","BATCH_SIZE = 32\n","LEARNING_RATE = 2e-5\n","NUM_TRAIN_EPOCHS = 3.0\n","# Warmup is a period of time where the learning rate \n","# is small and gradually increases--usually helps training.\n","WARMUP_PROPORTION = 0.1\n","# Model configs\n","SAVE_CHECKPOINTS_STEPS = 500\n","SAVE_SUMMARY_STEPS = 100"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"emHf9GhfWBZ_","colab_type":"code","colab":{}},"source":["# Compute # train and warmup steps from batch size\n","num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n","num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oEJldMr3WYZa","colab_type":"code","colab":{}},"source":["# Specify output directory and number of checkpoint steps to save\n","run_config = tf.estimator.RunConfig(\n","    model_dir=OUTPUT_DIR,\n","    save_summary_steps=SAVE_SUMMARY_STEPS,\n","    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q_WebpS1X97v","colab_type":"code","outputId":"816ce859-1138-43f3-a429-f77fa52229bb","executionInfo":{"status":"ok","timestamp":1572927571839,"user_tz":480,"elapsed":652,"user":{"displayName":"Divya Sudhakar","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBAEe8lSbL-gO8W2QGjfXvHbFVw-wl2B28bQD3_6_A=s64","userId":"13661723492181317645"}},"colab":{"base_uri":"https://localhost:8080/","height":275}},"source":["model_fn = model_fn_builder(\n","  num_labels=len(label_list),\n","  learning_rate=LEARNING_RATE,\n","  num_train_steps=num_train_steps,\n","  num_warmup_steps=num_warmup_steps)\n","\n","estimator = tf.estimator.Estimator(\n","  model_fn=model_fn,\n","  config=run_config,\n","  params={\"batch_size\": BATCH_SIZE})\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': 'model_out', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f074829d978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': 'model_out', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f074829d978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"NOO3RfG1DYLo","colab_type":"text"},"source":["Next we create an input builder function that takes our training feature set (`train_features`) and produces a generator. This is a pretty standard design pattern for working with Tensorflow [Estimators](https://www.tensorflow.org/guide/estimators)."]},{"cell_type":"code","metadata":{"id":"1Pv2bAlOX_-K","colab_type":"code","colab":{}},"source":["# Create an input function for training. drop_remainder = True for using TPUs.\n","train_input_fn = bert.run_classifier.input_fn_builder(\n","    features=train_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=True,\n","    drop_remainder=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t6Nukby2EB6-","colab_type":"text"},"source":["Now we train our model! For me, using a Colab notebook running on Google's GPUs, my training time was about 50 minutes."]},{"cell_type":"code","metadata":{"id":"nucD4gluYJmK","colab_type":"code","outputId":"2f4a235c-311c-4beb-970b-1678d51f3674","executionInfo":{"status":"error","timestamp":1572222512044,"user_tz":420,"elapsed":1728626,"user":{"displayName":"Divya Sudhakar","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBAEe8lSbL-gO8W2QGjfXvHbFVw-wl2B28bQD3_6_A=s64","userId":"13661723492181317645"}},"colab":{"base_uri":"https://localhost:8080/","height":870}},"source":["print(f'Beginning Training!')\n","current_time = datetime.now()\n","estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n","print(\"Training took time \", datetime.now() - current_time)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Beginning Training!\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n","/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Create CheckpointSaverHook.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Create CheckpointSaverHook.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 0 into model_out/model.ckpt.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 0 into model_out/model.ckpt.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.81457675, step = 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.81457675, step = 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 0.590818\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 0.590818\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.4095078, step = 100 (169.263 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.4095078, step = 100 (169.263 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 0.65301\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 0.65301\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.34616083, step = 200 (153.134 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.34616083, step = 200 (153.134 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 0.654046\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 0.654046\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.4483933, step = 300 (152.900 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.4483933, step = 300 (152.900 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 0.653324\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 0.653324\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.22259277, step = 400 (153.061 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.22259277, step = 400 (153.061 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 500 into model_out/model.ckpt.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 500 into model_out/model.ckpt.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 0.627116\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 0.627116\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.28096193, step = 500 (159.456 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.28096193, step = 500 (159.456 sec)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"CmbLTVniARy3","colab_type":"text"},"source":["Now let's use our dev data to see how well our model did:"]},{"cell_type":"code","metadata":{"id":"JIhejfpyJ8Bx","colab_type":"code","colab":{}},"source":["dev_input_fn = run_classifier.input_fn_builder(\n","    features=dev_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=False,\n","    drop_remainder=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PPVEXhNjYXC-","colab_type":"code","outputId":"2adf4e23-f82f-40b9-bae4-468d77a19dd8","executionInfo":{"status":"ok","timestamp":1572927627998,"user_tz":480,"elapsed":43176,"user":{"displayName":"Divya Sudhakar","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBAEe8lSbL-gO8W2QGjfXvHbFVw-wl2B28bQD3_6_A=s64","userId":"13661723492181317645"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["estimator.evaluate(input_fn=dev_input_fn, steps=None)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Could not find trained model in model_dir: model_out, running initialization to evaluate.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Could not find trained model in model_dir: model_out, running initialization to evaluate.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-13-ca03218f28a6>:34: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-13-ca03218f28a6>:34: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/metrics/python/metrics/classification.py:162: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/metrics/python/metrics/classification.py:162: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Starting evaluation at 2019-11-05T04:19:58Z\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Starting evaluation at 2019-11-05T04:19:58Z\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished evaluation at 2019-11-05-04:20:25\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished evaluation at 2019-11-05-04:20:25\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving dict for global step 0: auc = 0.47425184, eval_accuracy = 0.674, f1_score = 0.87005645, false_negatives = 120.0, false_positives = 206.0, global_step = 0, loss = 0.6517971, precision = 0.75934577, recall = 0.84415585, true_negatives = 24.0, true_positives = 650.0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving dict for global step 0: auc = 0.47425184, eval_accuracy = 0.674, f1_score = 0.87005645, false_negatives = 120.0, false_positives = 206.0, global_step = 0, loss = 0.6517971, precision = 0.75934577, recall = 0.84415585, true_negatives = 24.0, true_positives = 650.0\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["{'auc': 0.47425184,\n"," 'eval_accuracy': 0.674,\n"," 'f1_score': 0.87005645,\n"," 'false_negatives': 120.0,\n"," 'false_positives': 206.0,\n"," 'global_step': 0,\n"," 'loss': 0.6517971,\n"," 'precision': 0.75934577,\n"," 'recall': 0.84415585,\n"," 'true_negatives': 24.0,\n"," 'true_positives': 650.0}"]},"metadata":{"tags":[]},"execution_count":21}]}]}